{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['train_with_label.csv', 'test.csv', 'train.csv', 'sample_submission.csv']"
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm.notebook import tqdm\n",
    "import gensim\n",
    "import os\n",
    "from sklearn import preprocessing \n",
    "os.listdir(\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((24842, 6), (24843, 5), (24843, 2))"
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")\n",
    "sub = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "train.shape, test.shape, sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(49685, 6)"
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "df = pd.concat([train, test])\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"words\"] = df[\"product_name\"].apply(lambda words : words.lower().replace(\",\", \"\").replace(\"&\", \"\").split(\" \"))\n",
    "df[\"bigram\"] = df.words.apply(lambda words: [f'{words[i]} {words[i+1]}' for i in range(len(words)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = df.department_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {\n",
    "    'cluster_0': [2,3,4,7,8,9,14,16],\n",
    "    'cluster_1': [0,11,19],\n",
    "    'cluster_2': [5,12],\n",
    "    'cluster_3': [1,10,17],\n",
    "    'cluster_4': [13,18],\n",
    "    'cluster_5': [6,15,18,20]\n",
    "}\n",
    "\n",
    "for clm, c in clusters.items():\n",
    "    df[clm] = df.target.isin([Id+1 for Id in c]) * df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "counter = defaultdict(Counter)\n",
    "\n",
    "for e in df.itertuples():\n",
    "    counter[e.target].update([word for word in e.bigram if word != \"\"])\n",
    "        \n",
    "keywords = {}\n",
    "\n",
    "for i in range(21):\n",
    "    mc = counter[i].most_common(19)\n",
    "    keywords[i] = [c[0] for c in mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_feature = [f\"keyword_{i}\" for i in range(21)]\n",
    "\n",
    "for i in range(21):\n",
    "    df[f\"keyword_{i}\"] = df.bigram.apply(lambda words : len(set(words) & set(keywords[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "## 訓練済みの単語ベクトルを読み込んで，product_nameに含まれる単語をベクトルに変換して平均を取ることで，各product_idに対して特徴量ベクトルを作成する\n",
    "\n",
    "## gensimで.vecから読み込むときに時間がかかるので，他のnotebookでpickleで保存したものを使用している\n",
    "model = pd.read_pickle(\"../fast-text/fasttext_gensim_model.pkl\") \n",
    "\n",
    "unused_words = defaultdict(int)\n",
    "\n",
    "def get_weight(x):\n",
    "    weight = np.zeros(len(x)) + 1\n",
    "\n",
    "    for i in range(len(x)):\n",
    "        if x[i] in ['sleep']:\n",
    "            weight[i] *= 100\n",
    "\n",
    "    for i in range(len(x)-1):\n",
    "        bigram = f\"{x[i]} {x[i+1]}\"\n",
    "        if bigram in keywords:\n",
    "            weight[i] *= 100\n",
    "            weight[i+1] *= 100\n",
    "\n",
    "    return weight\n",
    "\n",
    "def to_vec(x, model):\n",
    "\n",
    "    weight = get_weight(x)\n",
    "\n",
    "    v = np.zeros(model.vector_size)\n",
    "    for i, w in enumerate(x):\n",
    "        try:\n",
    "            v += model[w] ## 単語が訓練済みモデルのvocabにあったら\n",
    "        except:\n",
    "            unused_words[w] += 1 ## ベクトルが存在しなかった単語をメモ\n",
    "    v = v / (np.sqrt(np.sum(v ** 2)) + 1e-16) ## 長さを1に正規化\n",
    "    return v    \n",
    "\n",
    "vecs = df[\"words\"].apply(lambda x : to_vec(x, model))\n",
    "vecs = np.vstack(vecs)\n",
    "fasttext_pretrain_cols = [f\"fasttext_pretrain_vec{k}\" for k in range(vecs.shape[1])]\n",
    "vec_df = pd.DataFrame(vecs, columns=fasttext_pretrain_cols)\n",
    "df = pd.concat([df, vec_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fasttext_pretrain_cols + keywords_feature + [\"order_rate\", \"order_dow_mode\", \"order_hour_of_day_mode\"] ## 予測に使用する特徴量の名前\n",
    "target = 'target'\n",
    "n_split = 5 ## cross validationのfold数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[~df[target].isna()]\n",
    "test = df[df[target].isna()]\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "train[features] = scaler.fit_transform(train[features])\n",
    "test[features] = scaler.transform(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--------fold 0-------\n{'logloss': 1.043306863120747, 'f1_micro': 0.775206278929362}\n--------fold 1-------\n{'logloss': 1.0348778412014643, 'f1_micro': 0.7806399678003623}\n--------fold 2-------\n{'logloss': 1.105392933011298, 'f1_micro': 0.7729468599033816}\n--------fold 3-------\n{'logloss': 1.0663898314479259, 'f1_micro': 0.7707326892109501}\n--------fold 4-------\n{'logloss': 1.0423703567385847, 'f1_micro': 0.7763687600644124}\n"
    }
   ],
   "source": [
    "## cross validation\n",
    "scores = []\n",
    "val_list = []\n",
    "preds_test = []\n",
    "pred_cluster = []\n",
    "\n",
    "kfold = KFold(n_splits=n_split, shuffle = True, random_state=42)\n",
    "\n",
    "for i_fold, (train_idx, valid_idx) in enumerate(kfold.split(train)):\n",
    "    print(f\"--------fold {i_fold}-------\")\n",
    "        \n",
    "    ## train data\n",
    "    x_tr = train.loc[train_idx, features]\n",
    "    y_tr = train.loc[train_idx, target]\n",
    "\n",
    "    ## valid data\n",
    "    x_va = train.loc[valid_idx, features]\n",
    "    y_va = train.loc[valid_idx, target]\n",
    "\n",
    "    ## train LGBM model\n",
    "    model = LGBMClassifier(colsample_bytree=0.2, subsample=0.8, class_weight='balanced', n_estimators=500)\n",
    "    model.fit(x_tr, y_tr, )\n",
    "    \n",
    "    ## predict on valid\n",
    "    pred_val = model.predict_proba(x_va)\n",
    "    pred_cls = model.predict(x_va)\n",
    "\n",
    "    ## evaluate\n",
    "    score = {\n",
    "        \"logloss\"  : log_loss(y_va, pred_val),\n",
    "        \"f1_micro\" : f1_score(y_va, pred_cls, average = \"micro\")}\n",
    "    print(score)\n",
    "    scores.append(score)\n",
    "\n",
    "    ## predict on test\n",
    "    pred_test = model.predict_proba(test[features])\n",
    "    preds_test.append(pred_test)\n",
    "\n",
    "    probe = pd.DataFrame(pred_val.round(3), index=y_va.index, columns=[f\"probe_{i}\" for i in range(21)])\n",
    "    df_new = df.loc[y_va.index, ['product_name', 'order_rate', 'order_dow_mode', 'order_hour_of_day_mode', 'department_id']]\n",
    "    df_new['label'] = pd.Series(np.argmax(pred_val, axis = 1), index=y_va.index)\n",
    "    val_list.append(pd.concat([df_new, probe], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    logloss  f1_micro\n0  1.043307  0.775206\n1  1.034878  0.780640\n2  1.105393  0.772947\n3  1.066390  0.770733\n4  1.042370  0.776369",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>logloss</th>\n      <th>f1_micro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.043307</td>\n      <td>0.775206</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.034878</td>\n      <td>0.780640</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.105393</td>\n      <td>0.772947</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.066390</td>\n      <td>0.770733</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.042370</td>\n      <td>0.776369</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "# マイクロ平均：ラベル全体でF1スコアを計算する\n",
    "# logloss：1を超える?\n",
    "\n",
    "score_df = pd.DataFrame(scores)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(val_list, axis=0).to_csv('../data/train_with_label.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   product_id  department_id\n0       24842             18\n1       24843              6\n2       24844              6\n3       24845              6\n4       24846             12",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_id</th>\n      <th>department_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>24842</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24843</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>24844</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>24845</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24846</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "## cvの各foldで計算した予測値の平均を最終的な予測値に\n",
    "pred_test_final = np.array(preds_test).mean(axis = 0)\n",
    "pred_test_final = np.argmax(pred_test_final, axis = 1)\n",
    "\n",
    "sub[\"department_id\"] = pred_test_final\n",
    "sub.to_csv(\"submission.csv\", index = False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594554163139",
   "display_name": "Python 3.8.2 64-bit ('.venv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}